{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "sys.path.append('/Users/matangrinberg/Library/CloudStorage/GoogleDrive-matan.grinberg@gmail.com/My Drive/(21-24) University of California, Berkeley/ML HEP/parametrized-classifiers/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library imports\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "\n",
    "# standard numerical library imports\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# energyflow imports\n",
    "import energyflow as ef\n",
    "from energyflow.archs import PFN\n",
    "from energyflow.utils import data_split, remap_pids, to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Global plot settings\n",
    "# from matplotlib import rc\n",
    "# import matplotlib.font_manager\n",
    "# rc('font', family='serif')\n",
    "# rc('text', usetex=True)\n",
    "# rc('font', size=22) \n",
    "# rc('xtick', labelsize=15) \n",
    "# rc('ytick', labelsize=15) \n",
    "# rc('legend', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize pT and center (y, phi)\n",
    "def normalize(x):\n",
    "    mask = x[:,0] > 0\n",
    "    yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0)\n",
    "    x[mask,1:3] -= yphi_avg\n",
    "    x[mask,0] /= x[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X):\n",
    "    for x in X:\n",
    "        normalize(x)\n",
    "    \n",
    "    # Remap PIDs to unique values in range [0,1]\n",
    "    remap_pids(X, pid_i=3, error_on_unknown=False)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to downloaded data from Zenodo\n",
    "data_dir = '/global/home/users/mgrinberg/parametrized-classifiers/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load(data_dir + '1D_aLund_train.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset['X']\n",
    "Y = dataset['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess_data(X)\n",
    "Y = to_categorical(Y, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = data_split(X, Y, test=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1620000, 51, 7)\n",
      "(1620000, 2)\n",
      "(180000, 51, 7)\n",
      "(180000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# network architecture parameters\n",
    "Phi_sizes = (100,100, 128)\n",
    "F_sizes = (100,100, 100)\n",
    "\n",
    "dctr = PFN(input_dim=7, \n",
    "           Phi_sizes=Phi_sizes, F_sizes=F_sizes,\n",
    "           summary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_label = 'DCTR_ee_dijets_1D_aLund'\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint('./saved_models/' + save_label + '.h5', monitor='val_loss', verbose=2, save_best_only=True, mode='min')\n",
    "CSVLogger = keras.callbacks.CSVLogger('./logs/' + save_label + '_loss.csv', append=False)\n",
    "EarlyStopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "callbacks = [checkpoint, CSVLogger, EarlyStopping]\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/810 [============================>.] - ETA: 0s - loss: 0.7073 - acc: 0.5022\n",
      "Epoch 1: val_loss improved from inf to 0.69467, saving model to ./saved_models/DCTR_ee_dijets_1D_aLund.h5\n",
      "810/810 [==============================] - 7s 6ms/step - loss: 0.7072 - acc: 0.5022 - val_loss: 0.6947 - val_acc: 0.5037\n",
      "Epoch 2/100\n",
      "803/810 [============================>.] - ETA: 0s - loss: 0.6943 - acc: 0.5028\n",
      "Epoch 2: val_loss improved from 0.69467 to 0.69392, saving model to ./saved_models/DCTR_ee_dijets_1D_aLund.h5\n",
      "810/810 [==============================] - 5s 6ms/step - loss: 0.6943 - acc: 0.5028 - val_loss: 0.6939 - val_acc: 0.5008\n",
      "Epoch 3/100\n",
      "809/810 [============================>.] - ETA: 0s - loss: 0.6935 - acc: 0.5040\n",
      "Epoch 3: val_loss improved from 0.69392 to 0.69361, saving model to ./saved_models/DCTR_ee_dijets_1D_aLund.h5\n",
      "810/810 [==============================] - 5s 6ms/step - loss: 0.6935 - acc: 0.5040 - val_loss: 0.6936 - val_acc: 0.5057\n",
      "Epoch 4/100\n",
      "803/810 [============================>.] - ETA: 0s - loss: 0.6934 - acc: 0.5039\n",
      "Epoch 4: val_loss improved from 0.69361 to 0.69306, saving model to ./saved_models/DCTR_ee_dijets_1D_aLund.h5\n",
      "810/810 [==============================] - 5s 6ms/step - loss: 0.6934 - acc: 0.5040 - val_loss: 0.6931 - val_acc: 0.5048\n",
      "Epoch 5/100\n",
      "802/810 [============================>.] - ETA: 0s - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 5: val_loss improved from 0.69306 to 0.69291, saving model to ./saved_models/DCTR_ee_dijets_1D_aLund.h5\n",
      "810/810 [==============================] - 5s 7ms/step - loss: 0.6932 - acc: 0.5050 - val_loss: 0.6929 - val_acc: 0.5085\n",
      "Epoch 6/100\n",
      "809/810 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5061\n",
      "Epoch 6: val_loss improved from 0.69291 to 0.69288, saving model to ./saved_models/DCTR_ee_dijets_1D_aLund.h5\n",
      "810/810 [==============================] - 5s 6ms/step - loss: 0.6931 - acc: 0.5061 - val_loss: 0.6929 - val_acc: 0.5074\n",
      "Epoch 7/100\n",
      "806/810 [============================>.] - ETA: 0s - loss: 0.6930 - acc: 0.5060\n",
      "Epoch 7: val_loss did not improve from 0.69288\n",
      "810/810 [==============================] - 5s 6ms/step - loss: 0.6930 - acc: 0.5060 - val_loss: 0.6930 - val_acc: 0.5048\n",
      "Epoch 8/100\n",
      "802/810 [============================>.] - ETA: 0s - loss: 0.6930 - acc: 0.5070\n",
      "Epoch 8: val_loss did not improve from 0.69288\n",
      "810/810 [==============================] - 5s 6ms/step - loss: 0.6930 - acc: 0.5070 - val_loss: 0.6931 - val_acc: 0.5024\n",
      "Epoch 9/100\n",
      "806/810 [============================>.] - ETA: 0s - loss: 0.6930 - acc: 0.5068\n",
      "Epoch 9: val_loss did not improve from 0.69288\n",
      "810/810 [==============================] - 5s 6ms/step - loss: 0.6930 - acc: 0.5068 - val_loss: 0.6930 - val_acc: 0.5088\n",
      "Epoch 10/100\n",
      "810/810 [==============================] - ETA: 0s - loss: 0.6929 - acc: 0.5072\n",
      "Epoch 10: val_loss did not improve from 0.69288\n",
      "810/810 [==============================] - 5s 6ms/step - loss: 0.6929 - acc: 0.5072 - val_loss: 0.6930 - val_acc: 0.5059\n",
      "Epoch 11/100\n",
      "809/810 [============================>.] - ETA: 0s - loss: 0.6929 - acc: 0.5076\n",
      "Epoch 11: val_loss improved from 0.69288 to 0.69279, saving model to ./saved_models/DCTR_ee_dijets_1D_aLund.h5\n",
      "810/810 [==============================] - 5s 6ms/step - loss: 0.6929 - acc: 0.5077 - val_loss: 0.6928 - val_acc: 0.5097\n",
      "Epoch 12/100\n",
      "808/810 [============================>.] - ETA: 0s - loss: 0.6929 - acc: 0.5070\n",
      "Epoch 12: val_loss did not improve from 0.69279\n",
      "810/810 [==============================] - 5s 6ms/step - loss: 0.6929 - acc: 0.5071 - val_loss: 0.6928 - val_acc: 0.5099\n",
      "Epoch 13/100\n",
      "809/810 [============================>.] - ETA: 0s - loss: 0.6929 - acc: 0.5071\n",
      "Epoch 13: val_loss did not improve from 0.69279\n",
      "810/810 [==============================] - 5s 6ms/step - loss: 0.6929 - acc: 0.5071 - val_loss: 0.6931 - val_acc: 0.5069\n",
      "Epoch 14/100\n",
      "803/810 [============================>.] - ETA: 0s - loss: 0.6929 - acc: 0.5078\n",
      "Epoch 14: val_loss did not improve from 0.69279\n",
      "810/810 [==============================] - 5s 6ms/step - loss: 0.6929 - acc: 0.5077 - val_loss: 0.6930 - val_acc: 0.5077\n",
      "Epoch 15/100\n",
      "810/810 [==============================] - ETA: 0s - loss: 0.6929 - acc: 0.5082\n",
      "Epoch 15: val_loss did not improve from 0.69279\n",
      "810/810 [==============================] - 5s 6ms/step - loss: 0.6929 - acc: 0.5082 - val_loss: 0.6928 - val_acc: 0.5088\n",
      "Epoch 16/100\n",
      "809/810 [============================>.] - ETA: 0s - loss: 0.6928 - acc: 0.5089\n",
      "Epoch 16: val_loss did not improve from 0.69279\n",
      "810/810 [==============================] - 5s 6ms/step - loss: 0.6928 - acc: 0.5089 - val_loss: 0.6929 - val_acc: 0.5105\n",
      "Epoch 17/100\n",
      "810/810 [==============================] - ETA: 0s - loss: 0.6928 - acc: 0.5082\n",
      "Epoch 17: val_loss did not improve from 0.69279\n",
      "810/810 [==============================] - 5s 6ms/step - loss: 0.6928 - acc: 0.5082 - val_loss: 0.6928 - val_acc: 0.5092\n",
      "Epoch 18/100\n",
      "804/810 [============================>.] - ETA: 0s - loss: 0.6928 - acc: 0.5087\n",
      "Epoch 18: val_loss did not improve from 0.69279\n",
      "810/810 [==============================] - 5s 6ms/step - loss: 0.6928 - acc: 0.5087 - val_loss: 0.6929 - val_acc: 0.5079\n",
      "Epoch 19/100\n",
      "810/810 [==============================] - ETA: 0s - loss: 0.6928 - acc: 0.5088\n",
      "Epoch 19: val_loss did not improve from 0.69279\n",
      "810/810 [==============================] - 5s 6ms/step - loss: 0.6928 - acc: 0.5088 - val_loss: 0.6928 - val_acc: 0.5084\n",
      "Epoch 20/100\n",
      "802/810 [============================>.] - ETA: 0s - loss: 0.6928 - acc: 0.5089\n",
      "Epoch 20: val_loss did not improve from 0.69279\n",
      "810/810 [==============================] - 5s 6ms/step - loss: 0.6928 - acc: 0.5089 - val_loss: 0.6928 - val_acc: 0.5097\n",
      "Epoch 21/100\n",
      "810/810 [==============================] - ETA: 0s - loss: 0.6928 - acc: 0.5087\n",
      "Epoch 21: val_loss did not improve from 0.69279\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "810/810 [==============================] - 5s 6ms/step - loss: 0.6928 - acc: 0.5087 - val_loss: 0.6928 - val_acc: 0.5097\n",
      "Epoch 21: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = dctr.fit(X_train, Y_train,\n",
    "                    epochs = epochs,\n",
    "                    batch_size = batch_size,\n",
    "                    validation_data = (X_val, Y_val),\n",
    "                    verbose = 1, \n",
    "                    callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m],     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['loss'],     label = 'loss')\n",
    "plt.plot(history.history['val_loss'], label = 'val loss')\n",
    "plt.legend(loc=0)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from saved file\n",
    "dctr.model.load_weights('./saved_models/DCTR_ee_dijets_1D_aLund.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Curve Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddParams2Input(keras.layers.Layer):\n",
    "    \"\"\" Custom layer for tuning with DCTR: \n",
    "    Arguments:\n",
    "    - n_MC_params : (int) - the number of n_MC_params that are in X_dim\n",
    "    - default_MC_params : (list of floats) - default values for each of the MC parameters\n",
    "    - trainable_MC_params : (list of booleans) - True for parameters that you want to fit, false for parameters that should be fixed at default value\n",
    "\n",
    "    Usage: \n",
    "    Let X_dim be the input dimension of each particle to a PFN model, and n_MC_params be the number of MC parameters. \n",
    "    Defines a Layer that takes in an array of dimension \n",
    "    (batch_size, padded_multiplicity, X_dim - n_MC_params)\n",
    "    This layer appends each particle by the default_MC_params and makes then trainable or non-trainable based on trainable_MC_params\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_MC_params, default_MC_params, trainable_MC_params):\n",
    "        super(AddParams2Input, self).__init__()\n",
    "        # Definitions\n",
    "        self.n_MC_params = n_MC_params\n",
    "        self.MC_params = default_MC_params\n",
    "        self.trainable_MC_params = trainable_MC_params\n",
    "\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # Convert input MC parameters to weights and make then trainable or non-trainable\n",
    "        for i in range(self.n_MC_params):\n",
    "            self.MC_params[i] = self.add_weight(name='MC_param_{}'.format(i), \n",
    "                                                shape=(1, 1),\n",
    "                                                initializer=keras.initializers.Constant(self.MC_params[i]),\n",
    "                                                trainable=self.trainable_MC_params[i])\n",
    "            \n",
    "        self.MC_params = keras.backend.tf.concat(self.MC_params, axis = -1)\n",
    "        super(AddParams2Input, self).build(input_shape)\n",
    "    \n",
    "    def call(self, input):\n",
    "        # Add MC params to each input particle (but not to the padded rows)\n",
    "        concat = tf.transpose(keras.backend.tf.where(keras.backend.abs(input[..., 0]) > 0,\n",
    "                                                 tf.transpose(self.MC_params * keras.backend.ones_like(input[..., 0:self.n_MC_params])),\n",
    "                                                tf.transpose(keras.backend.zeros_like(input[..., 0:self.n_MC_params]))))\n",
    "        return keras.backend.concatenate([input, concat], -1)\n",
    "        \n",
    "        # concat_input_and_params = keras.backend.tf.where(keras.backend.abs(input[...,0])>0,\n",
    "        #                                                  self.MC_params*keras.backend.ones_like(input[...,0:self.n_MC_params]),\n",
    "        #                                                  keras.backend.zeros_like(input[...,0:self.n_MC_params]))\n",
    "        # return keras.backend.concatenate([input, concat_input_and_params], -1)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1]+self.n_MC_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DCTR_fit_model(DCTR_model, \n",
    "                       X_dim, \n",
    "                       n_MC_params, \n",
    "                       default_MC_params,\n",
    "                       trainable_MC_params):\n",
    "    \"\"\" \n",
    "    Get a DCTR model that trains on the input MC parameters\n",
    "    \n",
    "    Arguments:\n",
    "    - DCTR_model : a PFN model that has been trained on a to continuously interpolate over the input MC dimensions\n",
    "    - X_dim : (int) - the dimension of the input expected by DCTR_model\n",
    "    - n_MC_params : (int) - the number of n_MC_params that are in X_dim\n",
    "    - default_MC_params : (list of floats) - default values for each of the MC parameters\n",
    "    - trainable_MC_params : (list of booleans) - True for parameters that you want to fit, false for parameters that should be fixed at default value\n",
    "\n",
    "    Returns:\n",
    "    - DCTR_fit_model: a compiled model that gradient descends only on the trainable MC parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # Do sanity checks on inputs\n",
    "    assert X_dim >=n_MC_params, \"X_dim must be larger than n_MC_params. X_dim includes the dimensionality of the 4-vector + number of MC parameters\"\n",
    "    assert n_MC_params == len(default_MC_params), \"Dimension mismatch between n_MC_params and number of default MC parameters given. len(default_MC_params) must equal n_MC_params\"\n",
    "    assert n_MC_params == len(trainable_MC_params), \"Dimension mismatch between n_MC_params and trainable_MC_params. len(trainable_MC_params) must equal n_MC_params.\"\n",
    "    assert np.any(trainable_MC_params), \"All parameters are set to non-trainable.\"\n",
    "    \n",
    "    # Define input to DCTR_fit_model\n",
    "    non_param_input = keras.layers.Input((None, X_dim - n_MC_params))\n",
    "\n",
    "    # Construct layer that adds trainable and non-trainable parameters to the input\n",
    "    add_params_layer = AddParams2Input(n_MC_params, default_MC_params, trainable_MC_params)\n",
    "    time_dist     = keras.layers.TimeDistributed(add_params_layer, name='tdist')(non_param_input)     \n",
    "\n",
    "    # Set all weights in DCTR_model to non-trainable\n",
    "    for layer in DCTR_model.model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # get the graph and the weights from the DCTR_model\n",
    "    output = DCTR_model.model(inputs = time_dist)\n",
    "\n",
    "    # Define full model\n",
    "    DCTR_fit_model = fitmodel = keras.models.Model(inputs = non_param_input, outputs = output)\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(lr=1e-4)\n",
    "    \n",
    "    # Compile with loss function\n",
    "    DCTR_fit_model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n",
    "    \n",
    "    return DCTR_fit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, 4)]         0         \n",
      "                                                                 \n",
      " tdist (TimeDistributed)     (None, None, 7)           3         \n",
      "                                                                 \n",
      " model (Functional)          (None, 2)                 57130     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,133\n",
      "Trainable params: 1\n",
      "Non-trainable params: 57,132\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/clusterfs/ml4hep_nvme2/bpnachman/anaconda3/envs/ml4hep2/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "dctr_fit_model = get_DCTR_fit_model(dctr, \n",
    "                       X_dim =7, \n",
    "                       n_MC_params = 3, \n",
    "                       default_MC_params   = [0.1365, 0.68, 0.217], # default params for [alpha_s, aLund, StoUD]\n",
    "                       trainable_MC_params = [False, True, False]) # Only train aLund\n",
    "\n",
    "dctr_fit_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_MC_params(dctr_fit_model, MC_params):\n",
    "    alphaS, aLund, StoUD = MC_params\n",
    "    weights = [np.array([[alphaS]],   dtype=np.float32),\n",
    "               np.array([[aLund]],    dtype=np.float32),\n",
    "               np.array([[StoUD]], dtype=np.float32)]\n",
    "    dctr_fit_model.layers[1].set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.68]], dtype=float32),\n",
       " array([[0.1365]], dtype=float32),\n",
       " array([[0.217]], dtype=float32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dctr_fit_model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_dataset = np.load(data_dir + 'test1D_default.npz')\n",
    "unknown_dataset = np.load(data_dir + 'test1D_aLund.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_default \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefault_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m X_unknown \u001b[38;5;241m=\u001b[39m preprocess_data(unknown_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjet\u001b[39m\u001b[38;5;124m'\u001b[39m][:,:,:\u001b[38;5;241m4\u001b[39m])\n\u001b[1;32m      4\u001b[0m Y_default \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(X_unknown[:,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_data\u001b[39m(X):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X:\n\u001b[0;32m----> 3\u001b[0m         \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Remap PIDs to unique values in range [0,1]\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     remap_pids(X, pid_i\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, error_on_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize\u001b[39m(x):\n\u001b[1;32m      3\u001b[0m     mask \u001b[38;5;241m=\u001b[39m x[:,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m     yphi_avg \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     x[mask,\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m yphi_avg\n\u001b[1;32m      6\u001b[0m     x[mask,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m x[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/clusterfs/ml4hep_nvme2/bpnachman/anaconda3/envs/ml4hep2/lib/python3.8/site-packages/numpy/lib/function_base.py:519\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    516\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of weights not compatible with specified axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# setup wgt to broadcast along axis\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     wgt \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwgt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     wgt \u001b[38;5;241m=\u001b[39m wgt\u001b[38;5;241m.\u001b[39mswapaxes(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, axis)\n\u001b[1;32m    522\u001b[0m scl \u001b[38;5;241m=\u001b[39m wgt\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mresult_dtype)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mbroadcast_to\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/clusterfs/ml4hep_nvme2/bpnachman/anaconda3/envs/ml4hep2/lib/python3.8/site-packages/numpy/lib/stride_tricks.py:412\u001b[0m, in \u001b[0;36mbroadcast_to\u001b[0;34m(array, shape, subok)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_broadcast_to_dispatcher, module\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbroadcast_to\u001b[39m(array, shape, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    368\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Broadcast an array to a new shape.\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;124;03m           [1, 2, 3]])\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_broadcast_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreadonly\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/clusterfs/ml4hep_nvme2/bpnachman/anaconda3/envs/ml4hep2/lib/python3.8/site-packages/numpy/lib/stride_tricks.py:348\u001b[0m, in \u001b[0;36m_broadcast_to\u001b[0;34m(array, shape, subok, readonly)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall elements of broadcast shape must be non-\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    346\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    347\u001b[0m extras \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 348\u001b[0m it \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnditer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmulti_index\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrefs_ok\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzerosize_ok\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mextras\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_flags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreadonly\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitershape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m it:\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;66;03m# never really has writebackifcopy semantics\u001b[39;00m\n\u001b[1;32m    353\u001b[0m     broadcast \u001b[38;5;241m=\u001b[39m it\u001b[38;5;241m.\u001b[39mitviews[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_default = preprocess_data(default_dataset['jet'][:,:,:4])\n",
    "X_unknown = preprocess_data(unknown_dataset['jet'][:,:,:4])\n",
    "\n",
    "Y_default = np.zeros_like(X_unknown[:,0,0])\n",
    "Y_unknown = np.ones_like(X_unknown[:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fit = np.concatenate((X_default, X_unknown), axis = 0)\n",
    "\n",
    "Y_fit = np.concatenate((Y_default, Y_unknown), axis = 0)\n",
    "Y_fit = to_categorical(Y_fit, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fit, _, Y_fit, _ = data_split(X_fit, Y_fit, test=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Loss as a function of MC parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(X, Y, dctr_model, MC_params, batch_size = 1000):\n",
    "    model = get_DCTR_fit_model(dctr_model, X_dim=7, n_MC_params=3, default_MC_params=MC_params, trainable_MC_params = [False, True, False])\n",
    "    return model.evaluate(x=X, y = Y, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dctr_fit_model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 13s 7ms/step - loss: 0.6938\n",
      "1800/1800 [==============================] - 14s 8ms/step - loss: 0.6936\n",
      "1800/1800 [==============================] - 14s 8ms/step - loss: 0.6934\n",
      "1800/1800 [==============================] - 14s 8ms/step - loss: 0.6933\n",
      "1800/1800 [==============================] - 14s 8ms/step - loss: 0.6931\n",
      "1800/1800 [==============================] - 15s 8ms/step - loss: 0.6930\n",
      "1800/1800 [==============================] - 14s 8ms/step - loss: 0.6930\n",
      "1800/1800 [==============================] - 14s 8ms/step - loss: 0.6929\n",
      "1800/1800 [==============================] - 15s 8ms/step - loss: 0.6929\n",
      "1800/1800 [==============================] - 14s 8ms/step - loss: 0.6929\n",
      "1800/1800 [==============================] - 14s 8ms/step - loss: 0.6929\n",
      "1800/1800 [==============================] - 14s 8ms/step - loss: 0.6929\n",
      "1800/1800 [==============================] - 13s 7ms/step - loss: 0.6929\n",
      "1800/1800 [==============================] - 15s 8ms/step - loss: 0.6929\n",
      "1800/1800 [==============================] - 14s 8ms/step - loss: 0.6929\n",
      "1800/1800 [==============================] - 14s 8ms/step - loss: 0.6929\n",
      "1800/1800 [==============================] - 15s 8ms/step - loss: 0.6929\n",
      "1800/1800 [==============================] - 15s 8ms/step - loss: 0.6929\n",
      "1800/1800 [==============================] - 15s 8ms/step - loss: 0.6929\n",
      "1800/1800 [==============================] - 15s 8ms/step - loss: 0.6929\n",
      "1800/1800 [==============================] - 14s 8ms/step - loss: 0.6929\n"
     ]
    }
   ],
   "source": [
    "aLund_loss = np.array([(aLund, get_loss(X_fit, Y_fit, dctr, [0.1365, aLund, 0.217])) for aLund in np.linspace(0.6, 1.0, 21)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(*aLund_loss.T)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel(r'aLund = 0.80')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85999999])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_min_loss(losses, x0):\n",
    "    f = sp.interpolate.interp1d(losses[:,0], losses[:,1], fill_value=\"extrapolate\")\n",
    "    return sp.optimize.minimize(f, x0=x0)['x']\n",
    "\n",
    "get_min_loss(aLund_loss, x0=0.68)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune with Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.68]], dtype=float32),\n",
       " array([[0.1365]], dtype=float32),\n",
       " array([[0.217]], dtype=float32)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dctr_fit_model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_MC_params(dctr_fit_model, [0.68, 0.1365, 0.217])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_weights = keras.callbacks.LambdaCallback(on_epoch_end=lambda batch, logs: print(\"aLund fit = \", \n",
    "                                               dctr_fit_model.get_weights()[0][0][0]))\n",
    "fit_vals = [0.68]\n",
    "append_weights = keras.callbacks.LambdaCallback(on_epoch_end=lambda batch, logs: \n",
    "                                               fit_vals.append(dctr_fit_model.get_weights()[0][0][0]))\n",
    "\n",
    "callbacks = [print_weights, append_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/clusterfs/ml4hep_nvme2/bpnachman/anaconda3/envs/ml4hep2/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/clusterfs/ml4hep_nvme2/bpnachman/anaconda3/envs/ml4hep2/lib/python3.8/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/clusterfs/ml4hep_nvme2/bpnachman/anaconda3/envs/ml4hep2/lib/python3.8/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/clusterfs/ml4hep_nvme2/bpnachman/anaconda3/envs/ml4hep2/lib/python3.8/site-packages/keras/engine/training.py\", line 893, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/clusterfs/ml4hep_nvme2/bpnachman/anaconda3/envs/ml4hep2/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 539, in minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    File \"/clusterfs/ml4hep_nvme2/bpnachman/anaconda3/envs/ml4hep2/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 640, in apply_gradients\n        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n    File \"/clusterfs/ml4hep_nvme2/bpnachman/anaconda3/envs/ml4hep2/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/utils.py\", line 73, in filter_empty_gradients\n        raise ValueError(f\"No gradients provided for any variable: {variable}. \"\n\n    ValueError: No gradients provided for any variable: (['tdist/MC_param_1:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'tdist/MC_param_1:0' shape=(1, 1) dtype=float32>),).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdctr_fit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_fit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/clusterfs/ml4hep_nvme2/bpnachman/anaconda3/envs/ml4hep2/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filefxnigsa8.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/clusterfs/ml4hep_nvme2/bpnachman/anaconda3/envs/ml4hep2/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/clusterfs/ml4hep_nvme2/bpnachman/anaconda3/envs/ml4hep2/lib/python3.8/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/clusterfs/ml4hep_nvme2/bpnachman/anaconda3/envs/ml4hep2/lib/python3.8/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/clusterfs/ml4hep_nvme2/bpnachman/anaconda3/envs/ml4hep2/lib/python3.8/site-packages/keras/engine/training.py\", line 893, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/clusterfs/ml4hep_nvme2/bpnachman/anaconda3/envs/ml4hep2/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 539, in minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    File \"/clusterfs/ml4hep_nvme2/bpnachman/anaconda3/envs/ml4hep2/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 640, in apply_gradients\n        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n    File \"/clusterfs/ml4hep_nvme2/bpnachman/anaconda3/envs/ml4hep2/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/utils.py\", line 73, in filter_empty_gradients\n        raise ValueError(f\"No gradients provided for any variable: {variable}. \"\n\n    ValueError: No gradients provided for any variable: (['tdist/MC_param_1:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'tdist/MC_param_1:0' shape=(1, 1) dtype=float32>),).\n"
     ]
    }
   ],
   "source": [
    "dctr_fit_model.fit(X_fit, Y_fit,\n",
    "                   epochs=40, \n",
    "                   batch_size=10000,\n",
    "                   callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fit_vals, marker='o')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(r'aLund')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
