{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41cd7559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-10 15:05:36.714199: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-10 15:05:36.714233: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from scipy.stats import chi\n",
    "from scipy import stats\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from functions import mean_gen, varx_gen, vary_gen, spherical_data, test_on_integers, learn_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "272f6013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Seed\n",
    "rand_n = 12345\n",
    "\n",
    "# Single Point on Sphere\n",
    "n = 40000\n",
    "angles = np.array([1.3, 1.7])\n",
    "thetas, phis = angles[0] * np.ones(n), angles[1] * np.ones(n)\n",
    "x_train, x_test, y_train, y_test = spherical_data(n, thetas, phis, rand_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a01fe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-10 15:05:42.425196: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-10 15:05:42.425228: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-10 15:05:42.425249: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jupyter-matan): /proc/driver/nvidia/version does not exist\n",
      "2022-08-10 15:05:42.425586: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.ones_like (TFOpLambda)       (None, 2)            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici (None, 1)            0           tf.ones_like[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 2)            2           tf.__operators__.getitem[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 4)            0           input_2[0][0]                    \n",
      "                                                                 model[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 1)            17281       concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 17,283\n",
      "Trainable params: 2\n",
      "Non-trainable params: 17,281\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_interpolate = tf.keras.models.load_model('3dmodels/discrete_model_mth50_mph50')\n",
    "\n",
    "for l in model_interpolate.layers:\n",
    "    l.trainable=False\n",
    "    \n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "# Building model_angles which is used to train (theta, phi)\n",
    "inputs_hold = tf.keras.Input(shape=(1,))\n",
    "simple_linear = Dense(2, use_bias = False, kernel_initializer='ones')(inputs_hold)\n",
    "model_angles = Model(inputs = inputs_hold, outputs = simple_linear)\n",
    "\n",
    "# Building model_parmafinder, inputs, which takes the (x, y) and finds the best (theta, phi)\n",
    "raw_inputs = tf.keras.Input(shape=(2,))\n",
    "inputs = tf.keras.layers.concatenate([raw_inputs, model_angles(tf.ones_like(raw_inputs)[:,0:1])])\n",
    "output = model_interpolate(inputs)\n",
    "\n",
    "model_paramfinder = Model(inputs = raw_inputs, outputs = output)\n",
    "model_paramfinder.compile(loss=loss_fn, optimizer='Adam')\n",
    "model_paramfinder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd3d2a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discrete_model_th5_ph3 has loss 0.6751845678870159\n",
      "discrete_model_th3_ph3 has loss 0.6679355034291584\n",
      "discrete_model_th2_ph2 has loss 0.5877782896867955\n",
      "discrete_model_th1_ph1 has loss 0.6266451570210229\n",
      "discrete_model_th0_ph0 has loss 0.6942435518819838\n",
      "discrete_model_mth40_mph40 has loss 0.57290454970477\n"
     ]
    }
   ],
   "source": [
    "test_on_integers(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05c5dbb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-10 15:05:56.209897: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 2s 2ms/step - loss: 0.5861\n",
      "0 Fitted result:  tf.Tensor([1.2763753 1.3937037], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5758\n",
      "1 Fitted result:  tf.Tensor([1.300679  1.5269145], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5748\n",
      "2 Fitted result:  tf.Tensor([1.3203766 1.5680984], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5751\n",
      "3 Fitted result:  tf.Tensor([1.3380346 1.589419 ], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5748\n",
      "4 Fitted result:  tf.Tensor([1.3328549 1.6004454], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5749\n",
      "5 Fitted result:  tf.Tensor([1.3268574 1.5907892], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5742\n",
      "6 Fitted result:  tf.Tensor([1.3299806 1.5872574], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5747\n",
      "7 Fitted result:  tf.Tensor([1.3312306 1.5915618], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5749\n",
      "8 Fitted result:  tf.Tensor([1.3219234 1.589526 ], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5747\n",
      "9 Fitted result:  tf.Tensor([1.3341796 1.5765221], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5749\n",
      "10 Fitted result:  tf.Tensor([1.3309253 1.5917178], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5741\n",
      "11 Fitted result:  tf.Tensor([1.3242657 1.6037991], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5747\n",
      "12 Fitted result:  tf.Tensor([1.3294818 1.5860825], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5750\n",
      "13 Fitted result:  tf.Tensor([1.342428  1.5768993], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5749\n",
      "14 Fitted result:  tf.Tensor([1.3287804 1.6000652], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5746\n",
      "15 Fitted result:  tf.Tensor([1.3283391 1.5849189], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5747\n",
      "16 Fitted result:  tf.Tensor([1.3436294 1.5855111], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5743\n",
      "17 Fitted result:  tf.Tensor([1.3270859 1.606647 ], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5749\n",
      "18 Fitted result:  tf.Tensor([1.3349069 1.5922711], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5744\n",
      "19 Fitted result:  tf.Tensor([1.3427433 1.5954219], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5745\n",
      "20 Fitted result:  tf.Tensor([1.3316066 1.58482  ], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5744\n",
      "21 Fitted result:  tf.Tensor([1.3395241 1.6001196], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5749\n",
      "22 Fitted result:  tf.Tensor([1.3401859 1.585788 ], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5746\n",
      "23 Fitted result:  tf.Tensor([1.3418269 1.5733572], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5749\n",
      "24 Fitted result:  tf.Tensor([1.3242706 1.5916511], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5751\n",
      "25 Fitted result:  tf.Tensor([1.3266631 1.5755813], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5749\n",
      "26 Fitted result:  tf.Tensor([1.3277292 1.577808 ], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5745\n",
      "27 Fitted result:  tf.Tensor([1.3175554 1.583261 ], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5746\n",
      "28 Fitted result:  tf.Tensor([1.339469  1.5833459], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5748\n",
      "29 Fitted result:  tf.Tensor([1.3321238 1.5903382], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5746\n",
      "30 Fitted result:  tf.Tensor([1.3204132 1.5979854], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5745\n",
      "31 Fitted result:  tf.Tensor([1.3339397 1.6036898], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5742\n",
      "32 Fitted result:  tf.Tensor([1.3396504 1.6051428], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5748\n",
      "33 Fitted result:  tf.Tensor([1.337938  1.5972397], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5748\n",
      "34 Fitted result:  tf.Tensor([1.3334974 1.6018898], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5747\n",
      "35 Fitted result:  tf.Tensor([1.3395711 1.592827 ], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5748\n",
      "36 Fitted result:  tf.Tensor([1.3394009 1.5878682], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5751\n",
      "37 Fitted result:  tf.Tensor([1.3422023 1.5804383], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5745\n",
      "38 Fitted result:  tf.Tensor([1.3444687 1.5842588], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5748\n",
      "39 Fitted result:  tf.Tensor([1.3317785 1.58498  ], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5747\n",
      "40 Fitted result:  tf.Tensor([1.3256483 1.6120123], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5747\n",
      "41 Fitted result:  tf.Tensor([1.3298017 1.6008793], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5753\n",
      "42 Fitted result:  tf.Tensor([1.3315322 1.5928184], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5747\n",
      "43 Fitted result:  tf.Tensor([1.3417362 1.5989556], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5751\n",
      "44 Fitted result:  tf.Tensor([1.3374516 1.6025696], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5747\n",
      "45 Fitted result:  tf.Tensor([1.3319985 1.5966803], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5746\n",
      "46 Fitted result:  tf.Tensor([1.343723  1.5828569], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5748\n",
      "47 Fitted result:  tf.Tensor([1.3284866 1.5909352], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5747\n",
      "48 Fitted result:  tf.Tensor([1.3341286 1.5827104], shape=(2,), dtype=float32)\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5746\n",
      "49 Fitted result:  tf.Tensor([1.3347924 1.5832266], shape=(2,), dtype=float32)\n",
      "Average error %: 4.772684350609779\n"
     ]
    }
   ],
   "source": [
    "epochs, iterations, batch_size = 1, 50, 100\n",
    "\n",
    "weights = learn_parameters(model_paramfinder, x_train, y_train, iterations, epochs, batch_size)\n",
    "angle_errors = (angles - weights) / angles\n",
    "average_error = np.sum(np.abs(angle_errors)) / 2\n",
    "print('Average error %:', average_error * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "397c3dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5721967718613304\n"
     ]
    }
   ],
   "source": [
    "xr = model_interpolate(x_train).numpy().transpose()[0]\n",
    "y = model_interpolate(x_train)\n",
    "loss = np.sum(-y_train * np.log(xr) - (1-y_train) * np.log(1-xr)) / xr.shape[0]\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529269ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort(xr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "409e840f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5717564871746726\n"
     ]
    }
   ],
   "source": [
    "x_train_mod = np.copy(x_train)\n",
    "x_train_mod[:, 2] = x_train[:, 2]\n",
    "x_train_mod[:, 3] = x_train[:, 3] - .1\n",
    "xr_mod = model_interpolate(x_train_mod).numpy().transpose()[0]\n",
    "y_mod = model_interpolate(x_train_mod)\n",
    "loss_mod = np.sum(-y_train * np.log(xr_mod) - (1-y_train) * np.log(1-xr_mod)) / xr_mod.shape[0]\n",
    "print(loss_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c11af5f",
   "metadata": {},
   "source": [
    "# x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7971de4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
